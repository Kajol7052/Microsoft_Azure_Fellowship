{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "96816ed7-b08a-4ca3-abb9-f99880c3535d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n",
    "\n",
    "This notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "20feeca6-f018-4931-be4b-ff9aa8185eb5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class = \"ansiout\"><b>dbutils.widgets</b> provides utilities for working with notebook widgets. You can create\n",
       "different types of widgets and get their bound value.\n",
       "\n",
       "For more info about a method, use <b>dbutils.widgets.help(\"methodName\")</b>.\n",
       "    <h3></h3><b>combobox(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a combobox input widget with a given name, default value and choices<br /><b>dropdown(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a dropdown input widget a with given name, default value and choices<br /><b>get(name: String): String</b> -> Retrieves current value of an input widget<br /><b>getArgument(name: String, optional: String): String</b> -> (DEPRECATED) Equivalent to get<br /><b>multiselect(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a multiselect input widget with a given name, default value and choices<br /><b>remove(name: String): void</b> -> Removes an input widget from the notebook<br /><b>removeAll: void</b> -> Removes all widgets in the notebook<br /><b>text(name: String, defaultValue: String, label: String): void</b> -> Creates a text input widget with a given name and default value<br /><br /></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class = \"ansiout\"><b>dbutils.widgets</b> provides utilities for working with notebook widgets. You can create\ndifferent types of widgets and get their bound value.\n\nFor more info about a method, use <b>dbutils.widgets.help(\"methodName\")</b>.\n    <h3></h3><b>combobox(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a combobox input widget with a given name, default value and choices<br /><b>dropdown(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a dropdown input widget a with given name, default value and choices<br /><b>get(name: String): String</b> -> Retrieves current value of an input widget<br /><b>getArgument(name: String, optional: String): String</b> -> (DEPRECATED) Equivalent to get<br /><b>multiselect(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a multiselect input widget with a given name, default value and choices<br /><b>remove(name: String): void</b> -> Removes an input widget from the notebook<br /><b>removeAll: void</b> -> Removes all widgets in the notebook<br /><b>text(name: String, defaultValue: String, label: String): void</b> -> Creates a text input widget with a given name and default value<br /><br /></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.widgets.text(name=\"storage_account\", defaultValue= \" \", label= \"Storage Account String\")\n",
    "dbutils.widgets.text(name=\"container_name\", defaultValue= \" \", label= \"container Name\")\n",
    "dbutils.widgets.text(name=\"mount_path\",defaultValue=\" \",label=\"Mount Path\")\n",
    "dbutils.widgets.text(name=\"storage_account_key\", defaultValue= \"Ends with ==\", label= \"Storage Account key\")\n",
    "dbutils.widgets.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "022b78e4-2a93-4eb5-bd5a-2318e9441ed5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6482be4c-f067-47c9-b0ac-35c938b94601",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">4122\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">4122\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# File location and type\n",
    "file_location = \"/FileStore/tables/EmployeeData/CpuLogData*.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\n",
    "\n",
    "df = df.select(\"DateTime\",\"keyboard\",\"mouse\",\"user_name\")\\\n",
    "        .withColumn('Date', f.split(df['DateTime'], ' ').getItem(0))\\\n",
    "        .withColumn('Time', f.split(df['DateTime'], ' ').getItem(1))\\\n",
    "        .withColumn('DateTime', f.to_timestamp(df['DateTime']))\n",
    "print(df.count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bd82bb99-1479-4d5c-be10-8c36df0f1d44",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a view or table\n",
    "temp_table_name = \"CpuLogData\"\n",
    "df.createOrReplaceTempView(temp_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b5f66379-6f7f-42ec-8e82-d0e0926a1721",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th></tr></thead><tbody><tr><td>4122</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         4122
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "count(1)",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "/* Query the created temp table in a SQL cell */\n",
    "select count(*) from `CpuLogData`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5c7936dc-2f91-481a-a827-45774cab056f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "storage_account_name =dbutils.widgets.get(\"storage_account\")\n",
    "# Azure Storage Account Key\n",
    "storage_account_key =dbutils.widgets.get(\"storage_account_key\")\n",
    "\n",
    "# Azure Storage Account Source Container\n",
    "container = dbutils.widgets.get(\"container_name\")\n",
    "mount_path=dbutils.widgets.get(\"mount_path\")\n",
    "# Set the configuration details to read/write\n",
    "spark.conf.set(\"fs.azure.account.key.{0}.blob.core.windows.net\".format(storage_account_name), storage_account_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ed664d06-cccb-46df-b51a-45d95e2ae9c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">ExecutionError</span>                            Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-2916639903946428&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     10</span>   source <span class=\"ansi-blue-fg\">=</span> url<span class=\"ansi-blue-fg\">,</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     11</span>   mount_point <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;/mnt/&#34;</span><span class=\"ansi-blue-fg\">+</span>mountName<span class=\"ansi-blue-fg\">,</span>\n",
       "<span class=\"ansi-green-fg\">---&gt; 12</span><span class=\"ansi-red-fg\">   </span>extra_configs <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">{</span>config<span class=\"ansi-blue-fg\">:</span>sas<span class=\"ansi-blue-fg\">}</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     13</span> )\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     14</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/local_disk0/tmp/1614141210601-0/dbutils.py</span> in <span class=\"ansi-cyan-fg\">f_with_exception_handling</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    322</span>                     exc<span class=\"ansi-blue-fg\">.</span>__context__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    323</span>                     exc<span class=\"ansi-blue-fg\">.</span>__cause__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 324</span><span class=\"ansi-red-fg\">                     </span><span class=\"ansi-green-fg\">raise</span> exc\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    325</span>             <span class=\"ansi-green-fg\">return</span> f_with_exception_handling\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    326</span> \n",
       "\n",
       "<span class=\"ansi-red-fg\">ExecutionError</span>: An error occurred while calling o340.mount.\n",
       ": java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/mount1; nested exception is: \n",
       "\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/mount1\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:128)\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:68)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:470)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:295)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n",
       "\tat java.lang.Thread.run(Thread.java:748)\n",
       "Caused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/mount1\n",
       "\tat scala.Predef$.require(Predef.scala:281)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:404)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$1(MetadataManager.scala:670)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:504)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:659)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:412)\n",
       "\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:89)\n",
       "\tat com.databricks.backend.daemon.data.server.handler.CEMountHandler.receive(MountHandler.scala:141)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:97)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:96)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:392)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:96)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$3.applyOrElse(DbfsServerBackend.scala:288)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$3.applyOrElse(DbfsServerBackend.scala:248)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:53)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:80)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:80)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:49)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$4(UsageLogging.scala:432)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:240)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:235)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:232)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:16)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:277)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:270)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:16)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:413)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:339)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:16)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:48)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:648)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:648)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:570)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$4(JettyServer.scala:337)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:240)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:235)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:232)\n",
       "\tat com.databricks.rpc.JettyServer$.withAttributionContext(JettyServer.scala:161)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:277)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:270)\n",
       "\tat com.databricks.rpc.JettyServer$.withAttributionTags(JettyServer.scala:161)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:325)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:264)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:539)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n",
       "\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n",
       "\t... 1 more\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ExecutionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2916639903946428&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     10</span>   source <span class=\"ansi-blue-fg\">=</span> url<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     11</span>   mount_point <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;/mnt/&#34;</span><span class=\"ansi-blue-fg\">+</span>mountName<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">---&gt; 12</span><span class=\"ansi-red-fg\">   </span>extra_configs <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">{</span>config<span class=\"ansi-blue-fg\">:</span>sas<span class=\"ansi-blue-fg\">}</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     13</span> )\n<span class=\"ansi-green-intense-fg ansi-bold\">     14</span> \n\n<span class=\"ansi-green-fg\">/local_disk0/tmp/1614141210601-0/dbutils.py</span> in <span class=\"ansi-cyan-fg\">f_with_exception_handling</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    322</span>                     exc<span class=\"ansi-blue-fg\">.</span>__context__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    323</span>                     exc<span class=\"ansi-blue-fg\">.</span>__cause__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-fg\">--&gt; 324</span><span class=\"ansi-red-fg\">                     </span><span class=\"ansi-green-fg\">raise</span> exc\n<span class=\"ansi-green-intense-fg ansi-bold\">    325</span>             <span class=\"ansi-green-fg\">return</span> f_with_exception_handling\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span> \n\n<span class=\"ansi-red-fg\">ExecutionError</span>: An error occurred while calling o340.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/mount1; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/mount1\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:128)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:68)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:470)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/mount1\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:404)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$1(MetadataManager.scala:670)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:504)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:659)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:412)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:89)\n\tat com.databricks.backend.daemon.data.server.handler.CEMountHandler.receive(MountHandler.scala:141)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:97)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:96)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:96)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$3.applyOrElse(DbfsServerBackend.scala:288)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$3.applyOrElse(DbfsServerBackend.scala:248)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:53)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:80)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:80)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:49)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$4(UsageLogging.scala:432)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:240)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:235)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:232)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:16)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:277)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:270)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:16)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:413)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:339)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:16)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:48)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:648)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:648)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:570)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$4(JettyServer.scala:337)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:240)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:235)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:232)\n\tat com.databricks.rpc.JettyServer$.withAttributionContext(JettyServer.scala:161)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:277)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:270)\n\tat com.databricks.rpc.JettyServer$.withAttributionTags(JettyServer.scala:161)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:325)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:264)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:539)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n\t... 1 more\n</div>",
       "errorSummary": "java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/mount1; nested exception is: ",
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.fs.mount(\n",
    "  source = url,\n",
    "  mount_point = \"/mnt/\"+mount_path,\n",
    "  extra_configs = {config:sas}\n",
    ")\n",
    "\n",
    "# python\n",
    "#df = spark.read.text(\"/mnt/\"+mountName+\"/raw_data.json\")\n",
    "#df = spark.read.option(\"multiline\", \"true\").json(\"/mnt/\"+mountName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "56cbe850-7784-4670-87d1-416919be9519",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>user_name</th><th>avg_active_hrs</th></tr></thead><tbody><tr><td>deepshukla292@gmail.com</td><td>06:35</td></tr><tr><td>iamnzm@outlook.com</td><td>06:22</td></tr><tr><td>sharlawar77@gmail.com</td><td>06:20</td></tr><tr><td>salinabodale73@gmail.com</td><td>06:06</td></tr><tr><td>rahilstar11@gmail.com</td><td>05:32</td></tr><tr><td>markfernandes66@gmail.com</td><td>05:24</td></tr><tr><td>bhagyashrichalke21@gmail.com</td><td>05:00</td></tr><tr><td>damodharn21@gmail.com</td><td>02:39</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "deepshukla292@gmail.com",
         "06:35"
        ],
        [
         "iamnzm@outlook.com",
         "06:22"
        ],
        [
         "sharlawar77@gmail.com",
         "06:20"
        ],
        [
         "salinabodale73@gmail.com",
         "06:06"
        ],
        [
         "rahilstar11@gmail.com",
         "05:32"
        ],
        [
         "markfernandes66@gmail.com",
         "05:24"
        ],
        [
         "bhagyashrichalke21@gmail.com",
         "05:00"
        ],
        [
         "damodharn21@gmail.com",
         "02:39"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "user_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "avg_active_hrs",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Query to Find users with lowest number of average hours and highest number of average hours '''\n",
    "\n",
    "avg_active_hrs  = sqlContext.sql(\"select user_name,from_unixtime(ROUND((count(*)*5)*60/6,2),'HH:mm') as avg_active_hrs from `CpuLogData` where keyboard!=0 or mouse!=0 group by user_name order by avg_active_hrs desc\")\n",
    "display(avg_active_hrs)\n",
    "#avg_active_hrs.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\") .option(\"inferSchema\", \"false\").option(\"delimiter\", \",\").save(url+\"/logging/active_hrs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "45ce1b90-cb2e-4ca4-adc1-8ae2d899bddf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>user_name</th><th>inactive_hrs</th></tr></thead><tbody><tr><td>iamnzm@outlook.com</td><td>02:09</td></tr><tr><td>rahilstar11@gmail.com</td><td>02:06</td></tr><tr><td>salinabodale73@gmail.com</td><td>01:47</td></tr><tr><td>sharlawar77@gmail.com</td><td>01:42</td></tr><tr><td>bhagyashrichalke21@gmail.com</td><td>01:40</td></tr><tr><td>markfernandes66@gmail.com</td><td>01:39</td></tr><tr><td>deepshukla292@gmail.com</td><td>01:15</td></tr><tr><td>damodharn21@gmail.com</td><td>00:51</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "iamnzm@outlook.com",
         "02:09"
        ],
        [
         "rahilstar11@gmail.com",
         "02:06"
        ],
        [
         "salinabodale73@gmail.com",
         "01:47"
        ],
        [
         "sharlawar77@gmail.com",
         "01:42"
        ],
        [
         "bhagyashrichalke21@gmail.com",
         "01:40"
        ],
        [
         "markfernandes66@gmail.com",
         "01:39"
        ],
        [
         "deepshukla292@gmail.com",
         "01:15"
        ],
        [
         "damodharn21@gmail.com",
         "00:51"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "user_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "inactive_hrs",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Query to Find users with highest number of idle hours '''\n",
    "\n",
    "avg_inactive_hrs = sqlContext.sql(\"select user_name,from_unixtime(ROUND((count(*)*5)*60/6,2),'HH:mm') as inactive_hrs from `CpuLogData` where keyboard=0 and mouse=0 group by user_name order by inactive_hrs desc\")\n",
    "display(avg_inactive_hrs)\n",
    "#avg_inactive_hrs.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\") .option(\"inferSchema\", \"false\").option(\"delimiter\", \",\").save(url+\"/logging/inactive_hrs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2a69a676-d315-4119-80c2-dffe4348669d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Date</th><th>DateTime</th></tr></thead><tbody><tr><td>2019-09-16</td><td>2019-09-16T12:55:01.000+0000</td></tr><tr><td>2019-09-17</td><td>2019-09-17T08:25:01.000+0000</td></tr><tr><td>2019-09-18</td><td>2019-09-18T08:30:01.000+0000</td></tr><tr><td>2019-09-19</td><td>2019-09-19T08:40:02.000+0000</td></tr><tr><td>2019-09-20</td><td>2019-09-20T09:05:01.000+0000</td></tr><tr><td>2019-09-21</td><td>2019-09-21T09:10:01.000+0000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2019-09-16",
         "2019-09-16T12:55:01.000+0000"
        ],
        [
         "2019-09-17",
         "2019-09-17T08:25:01.000+0000"
        ],
        [
         "2019-09-18",
         "2019-09-18T08:30:01.000+0000"
        ],
        [
         "2019-09-19",
         "2019-09-19T08:40:02.000+0000"
        ],
        [
         "2019-09-20",
         "2019-09-20T09:05:01.000+0000"
        ],
        [
         "2019-09-21",
         "2019-09-21T09:10:01.000+0000"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "DateTime",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "daily_session_start_time_df = sqlContext.sql(\"select Date,to_timestamp(min(DateTime)) as DateTime from CpuLogData group by Date order by Date\")\n",
    "temp_table_name = \"view_session_start_time\"\n",
    "daily_session_start_time_df.createOrReplaceTempView(temp_table_name)\n",
    "display(daily_session_start_time_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0f851e4b-0547-4335-884e-7b1679c8eb98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>user_name</th><th>Date</th><th>Datetime</th></tr></thead><tbody><tr><td>deepshukla292@gmail.com</td><td>2019-09-16</td><td>2019-09-16T13:00:01.000+0000</td></tr><tr><td>salinabodale73@gmail.com</td><td>2019-09-16</td><td>2019-09-16T12:55:02.000+0000</td></tr><tr><td>rahilstar11@gmail.com</td><td>2019-09-16</td><td>2019-09-16T13:00:03.000+0000</td></tr><tr><td>iamnzm@outlook.com</td><td>2019-09-16</td><td>2019-09-16T13:00:01.000+0000</td></tr><tr><td>bhagyashrichalke21@gmail.com</td><td>2019-09-16</td><td>2019-09-16T12:55:01.000+0000</td></tr><tr><td>sharlawar77@gmail.com</td><td>2019-09-16</td><td>2019-09-16T13:00:04.000+0000</td></tr><tr><td>markfernandes66@gmail.com</td><td>2019-09-17</td><td>2019-09-17T10:50:01.000+0000</td></tr><tr><td>deepshukla292@gmail.com</td><td>2019-09-17</td><td>2019-09-17T09:30:01.000+0000</td></tr><tr><td>sharlawar77@gmail.com</td><td>2019-09-17</td><td>2019-09-17T10:45:02.000+0000</td></tr><tr><td>salinabodale73@gmail.com</td><td>2019-09-17</td><td>2019-09-17T10:15:01.000+0000</td></tr><tr><td>rahilstar11@gmail.com</td><td>2019-09-17</td><td>2019-09-17T09:40:01.000+0000</td></tr><tr><td>iamnzm@outlook.com</td><td>2019-09-17</td><td>2019-09-17T08:35:01.000+0000</td></tr><tr><td>bhagyashrichalke21@gmail.com</td><td>2019-09-17</td><td>2019-09-17T10:10:02.000+0000</td></tr><tr><td>bhagyashrichalke21@gmail.com</td><td>2019-09-18</td><td>2019-09-18T10:15:01.000+0000</td></tr><tr><td>sharlawar77@gmail.com</td><td>2019-09-18</td><td>2019-09-18T09:05:01.000+0000</td></tr><tr><td>markfernandes66@gmail.com</td><td>2019-09-18</td><td>2019-09-18T09:00:01.000+0000</td></tr><tr><td>iamnzm@outlook.com</td><td>2019-09-18</td><td>2019-09-18T08:30:01.000+0000</td></tr><tr><td>rahilstar11@gmail.com</td><td>2019-09-18</td><td>2019-09-18T10:15:02.000+0000</td></tr><tr><td>salinabodale73@gmail.com</td><td>2019-09-18</td><td>2019-09-18T10:10:01.000+0000</td></tr><tr><td>deepshukla292@gmail.com</td><td>2019-09-18</td><td>2019-09-18T09:05:01.000+0000</td></tr><tr><td>bhagyashrichalke21@gmail.com</td><td>2019-09-19</td><td>2019-09-19T10:20:01.000+0000</td></tr><tr><td>salinabodale73@gmail.com</td><td>2019-09-19</td><td>2019-09-19T10:20:01.000+0000</td></tr><tr><td>markfernandes66@gmail.com</td><td>2019-09-19</td><td>2019-09-19T09:10:01.000+0000</td></tr><tr><td>deepshukla292@gmail.com</td><td>2019-09-19</td><td>2019-09-19T09:05:01.000+0000</td></tr><tr><td>damodharn21@gmail.com</td><td>2019-09-19</td><td>2019-09-19T10:35:03.000+0000</td></tr><tr><td>sharlawar77@gmail.com</td><td>2019-09-19</td><td>2019-09-19T10:10:01.000+0000</td></tr><tr><td>rahilstar11@gmail.com</td><td>2019-09-19</td><td>2019-09-19T10:30:08.000+0000</td></tr><tr><td>iamnzm@outlook.com</td><td>2019-09-19</td><td>2019-09-19T08:40:02.000+0000</td></tr><tr><td>iamnzm@outlook.com</td><td>2019-09-20</td><td>2019-09-20T10:00:01.000+0000</td></tr><tr><td>damodharn21@gmail.com</td><td>2019-09-20</td><td>2019-09-20T10:35:02.000+0000</td></tr><tr><td>sharlawar77@gmail.com</td><td>2019-09-20</td><td>2019-09-20T09:05:01.000+0000</td></tr><tr><td>rahilstar11@gmail.com</td><td>2019-09-20</td><td>2019-09-20T10:20:02.000+0000</td></tr><tr><td>markfernandes66@gmail.com</td><td>2019-09-20</td><td>2019-09-20T10:25:01.000+0000</td></tr><tr><td>salinabodale73@gmail.com</td><td>2019-09-20</td><td>2019-09-20T10:25:01.000+0000</td></tr><tr><td>bhagyashrichalke21@gmail.com</td><td>2019-09-20</td><td>2019-09-20T10:25:01.000+0000</td></tr><tr><td>salinabodale73@gmail.com</td><td>2019-09-21</td><td>2019-09-21T11:20:01.000+0000</td></tr><tr><td>markfernandes66@gmail.com</td><td>2019-09-21</td><td>2019-09-21T11:20:01.000+0000</td></tr><tr><td>deepshukla292@gmail.com</td><td>2019-09-21</td><td>2019-09-21T09:10:01.000+0000</td></tr><tr><td>bhagyashrichalke21@gmail.com</td><td>2019-09-21</td><td>2019-09-21T11:20:02.000+0000</td></tr><tr><td>sharlawar77@gmail.com</td><td>2019-09-21</td><td>2019-09-21T11:25:01.000+0000</td></tr><tr><td>damodharn21@gmail.com</td><td>2019-09-21</td><td>2019-09-21T11:40:03.000+0000</td></tr><tr><td>iamnzm@outlook.com</td><td>2019-09-21</td><td>2019-09-21T11:25:01.000+0000</td></tr><tr><td>rahilstar11@gmail.com</td><td>2019-09-21</td><td>2019-09-21T11:20:01.000+0000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "deepshukla292@gmail.com",
         "2019-09-16",
         "2019-09-16T13:00:01.000+0000"
        ],
        [
         "salinabodale73@gmail.com",
         "2019-09-16",
         "2019-09-16T12:55:02.000+0000"
        ],
        [
         "rahilstar11@gmail.com",
         "2019-09-16",
         "2019-09-16T13:00:03.000+0000"
        ],
        [
         "iamnzm@outlook.com",
         "2019-09-16",
         "2019-09-16T13:00:01.000+0000"
        ],
        [
         "bhagyashrichalke21@gmail.com",
         "2019-09-16",
         "2019-09-16T12:55:01.000+0000"
        ],
        [
         "sharlawar77@gmail.com",
         "2019-09-16",
         "2019-09-16T13:00:04.000+0000"
        ],
        [
         "markfernandes66@gmail.com",
         "2019-09-17",
         "2019-09-17T10:50:01.000+0000"
        ],
        [
         "deepshukla292@gmail.com",
         "2019-09-17",
         "2019-09-17T09:30:01.000+0000"
        ],
        [
         "sharlawar77@gmail.com",
         "2019-09-17",
         "2019-09-17T10:45:02.000+0000"
        ],
        [
         "salinabodale73@gmail.com",
         "2019-09-17",
         "2019-09-17T10:15:01.000+0000"
        ],
        [
         "rahilstar11@gmail.com",
         "2019-09-17",
         "2019-09-17T09:40:01.000+0000"
        ],
        [
         "iamnzm@outlook.com",
         "2019-09-17",
         "2019-09-17T08:35:01.000+0000"
        ],
        [
         "bhagyashrichalke21@gmail.com",
         "2019-09-17",
         "2019-09-17T10:10:02.000+0000"
        ],
        [
         "bhagyashrichalke21@gmail.com",
         "2019-09-18",
         "2019-09-18T10:15:01.000+0000"
        ],
        [
         "sharlawar77@gmail.com",
         "2019-09-18",
         "2019-09-18T09:05:01.000+0000"
        ],
        [
         "markfernandes66@gmail.com",
         "2019-09-18",
         "2019-09-18T09:00:01.000+0000"
        ],
        [
         "iamnzm@outlook.com",
         "2019-09-18",
         "2019-09-18T08:30:01.000+0000"
        ],
        [
         "rahilstar11@gmail.com",
         "2019-09-18",
         "2019-09-18T10:15:02.000+0000"
        ],
        [
         "salinabodale73@gmail.com",
         "2019-09-18",
         "2019-09-18T10:10:01.000+0000"
        ],
        [
         "deepshukla292@gmail.com",
         "2019-09-18",
         "2019-09-18T09:05:01.000+0000"
        ],
        [
         "bhagyashrichalke21@gmail.com",
         "2019-09-19",
         "2019-09-19T10:20:01.000+0000"
        ],
        [
         "salinabodale73@gmail.com",
         "2019-09-19",
         "2019-09-19T10:20:01.000+0000"
        ],
        [
         "markfernandes66@gmail.com",
         "2019-09-19",
         "2019-09-19T09:10:01.000+0000"
        ],
        [
         "deepshukla292@gmail.com",
         "2019-09-19",
         "2019-09-19T09:05:01.000+0000"
        ],
        [
         "damodharn21@gmail.com",
         "2019-09-19",
         "2019-09-19T10:35:03.000+0000"
        ],
        [
         "sharlawar77@gmail.com",
         "2019-09-19",
         "2019-09-19T10:10:01.000+0000"
        ],
        [
         "rahilstar11@gmail.com",
         "2019-09-19",
         "2019-09-19T10:30:08.000+0000"
        ],
        [
         "iamnzm@outlook.com",
         "2019-09-19",
         "2019-09-19T08:40:02.000+0000"
        ],
        [
         "iamnzm@outlook.com",
         "2019-09-20",
         "2019-09-20T10:00:01.000+0000"
        ],
        [
         "damodharn21@gmail.com",
         "2019-09-20",
         "2019-09-20T10:35:02.000+0000"
        ],
        [
         "sharlawar77@gmail.com",
         "2019-09-20",
         "2019-09-20T09:05:01.000+0000"
        ],
        [
         "rahilstar11@gmail.com",
         "2019-09-20",
         "2019-09-20T10:20:02.000+0000"
        ],
        [
         "markfernandes66@gmail.com",
         "2019-09-20",
         "2019-09-20T10:25:01.000+0000"
        ],
        [
         "salinabodale73@gmail.com",
         "2019-09-20",
         "2019-09-20T10:25:01.000+0000"
        ],
        [
         "bhagyashrichalke21@gmail.com",
         "2019-09-20",
         "2019-09-20T10:25:01.000+0000"
        ],
        [
         "salinabodale73@gmail.com",
         "2019-09-21",
         "2019-09-21T11:20:01.000+0000"
        ],
        [
         "markfernandes66@gmail.com",
         "2019-09-21",
         "2019-09-21T11:20:01.000+0000"
        ],
        [
         "deepshukla292@gmail.com",
         "2019-09-21",
         "2019-09-21T09:10:01.000+0000"
        ],
        [
         "bhagyashrichalke21@gmail.com",
         "2019-09-21",
         "2019-09-21T11:20:02.000+0000"
        ],
        [
         "sharlawar77@gmail.com",
         "2019-09-21",
         "2019-09-21T11:25:01.000+0000"
        ],
        [
         "damodharn21@gmail.com",
         "2019-09-21",
         "2019-09-21T11:40:03.000+0000"
        ],
        [
         "iamnzm@outlook.com",
         "2019-09-21",
         "2019-09-21T11:25:01.000+0000"
        ],
        [
         "rahilstar11@gmail.com",
         "2019-09-21",
         "2019-09-21T11:20:01.000+0000"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "user_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Datetime",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "daily_login_time_df = sqlContext.sql(\"select user_name,Date,min(DateTime) as Datetime from `CpuLogData` where (keyboard != 0 or mouse != 0) group by user_name,Date order by Date\")\n",
    "temp_table_name = \"view_daily_login_time\"\n",
    "daily_login_time_df.createOrReplaceTempView(temp_table_name)\n",
    "display(daily_login_time_df)\n",
    "#daily_login_time_df.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\") .option(\"inferSchema\", \"false\").option(\"delimiter\", \",\").save(url+\"/logging/active.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "02f80866-e910-4701-9743-273447968e8e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>user_name</th><th>average_late_time_in_hrs</th><th>num_of_late_comings</th></tr></thead><tbody><tr><td>markfernandes66@gmail.com</td><td>1Hour :9Min</td><td>5</td></tr><tr><td>sharlawar77@gmail.com</td><td>1Hour :8Min</td><td>5</td></tr><tr><td>salinabodale73@gmail.com</td><td>1Hour :27Min</td><td>6</td></tr><tr><td>bhagyashrichalke21@gmail.com</td><td>1Hour :27Min</td><td>5</td></tr><tr><td>rahilstar11@gmail.com</td><td>1Hour :23Min</td><td>6</td></tr><tr><td>damodharn21@gmail.com</td><td>0Hour :59Min</td><td>3</td></tr><tr><td>iamnzm@outlook.com</td><td>0Hour :34Min</td><td>4</td></tr><tr><td>deepshukla292@gmail.com</td><td>0Hour :22Min</td><td>4</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "markfernandes66@gmail.com",
         "1Hour :9Min",
         5
        ],
        [
         "sharlawar77@gmail.com",
         "1Hour :8Min",
         5
        ],
        [
         "salinabodale73@gmail.com",
         "1Hour :27Min",
         6
        ],
        [
         "bhagyashrichalke21@gmail.com",
         "1Hour :27Min",
         5
        ],
        [
         "rahilstar11@gmail.com",
         "1Hour :23Min",
         6
        ],
        [
         "damodharn21@gmail.com",
         "0Hour :59Min",
         3
        ],
        [
         "iamnzm@outlook.com",
         "0Hour :34Min",
         4
        ],
        [
         "deepshukla292@gmail.com",
         "0Hour :22Min",
         4
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "user_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "average_late_time_in_hrs",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "num_of_late_comings",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Query to find the highest number to times users late coming '''\n",
    "\n",
    "late_users_df = sqlContext.sql(\"select lut.user_name,Concat(cast(Round((Sum(lut.TimeDifference)/60)/6,2) AS INT), 'Hour :', Floor(Round((((Sum(lut.TimeDifference)/60)/6)%1)*60)), 'Min') as average_late_time_in_hrs,count(*) as num_of_late_comings from(Select lt.user_name,(unix_timestamp(lt.DateTime)-unix_timestamp(st.DateTime))/(60) as TimeDifference from view_daily_login_time as lt,view_session_start_time as st where lt.Date == st.Date) as lut where lut.TimeDifference != 0 group by lut.user_name order by average_late_time_in_hrs desc\")\n",
    "display(late_users_df)\n",
    "#spark.conf.set(\"fs.azure.account.key.\"+containerName+\".blob.core.windows.net\",\"P0Pm8ZZf1LcQu1PXJfhVv1OUGDmkrg1Btf1OwJ8wpLovqOq1RzQhmFmLKObQshkgR5IRRE2oUfSJpKEqUCcgkA==\")\n",
    "#late_users_df.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\") .option(\"inferSchema\", \"false\").option(\"delimiter\", \",\").save(url+\"/logging/latecomings.csv\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "SparkSQL",
   "notebookOrigID": 1259282462606627,
   "widgets": {
    "container_name": {
     "currentValue": " ",
     "nuid": "93015f89-58e3-4c00-9fb7-cb0052dce4c6",
     "widgetInfo": {
      "defaultValue": " ",
      "label": "container Name",
      "name": "container_name",
      "options": {
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "mount_path": {
     "currentValue": "mount1",
     "nuid": "d0ea5ad1-e2dc-485e-a018-ea8b36a1f382",
     "widgetInfo": {
      "defaultValue": " ",
      "label": "Mount Path",
      "name": "mount_path",
      "options": {
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "storage_account": {
     "currentValue": " ",
     "nuid": "d102ee1b-740d-4e68-a734-9e6fa4bfcc03",
     "widgetInfo": {
      "defaultValue": " ",
      "label": "Storage Account String",
      "name": "storage_account",
      "options": {
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "storage_account_key": {
     "currentValue": "Ends with ==",
     "nuid": "7c0ffa36-175f-49d1-85db-544d71efbe1d",
     "widgetInfo": {
      "defaultValue": "Ends with ==",
      "label": "Storage Account key",
      "name": "storage_account_key",
      "options": {
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
